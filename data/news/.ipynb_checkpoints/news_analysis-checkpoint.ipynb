{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f93545d-0a23-4969-906c-bb6d4700c517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\furka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\furka\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Haberlerin ortalama duygu puanı ve yorumu kaydedildi: data/news/haber_yorum.csv\n",
      "   ortalama_duygu_puani                                 yorum\n",
      "0              0.333333  Genel olarak olumsuz bir hava hakim.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "turkce_stopwords = set(nltk_stopwords.words('turkish'))\n",
    "ozel_stopwords = {\n",
    "    've', 'bir', 'bu', 'da', 'de', 'için', 'ile', 'ama', 'fakat', 'ancak', 'çünkü', 'gibi',\n",
    "    'mi', 'mı', 'mu', 'mü', 'ki', 'diye', 'ya', 'veya', 'ya da', 'daha', 'en', 'çok', 'az',\n",
    "    'olan', 'olduğu', 'olarak', 'ise', 'yani', 'hem', 'ne', 'niçin', 'neden', 'ben', 'sen',\n",
    "    'biz', 'siz', 'onlar', 'benim', 'senin', 'bizim', 'sizin', 'birçok', 'bazı', 'her', 'hiç',\n",
    "    'şey', 'şu', 'o', 'tüm', 'hepsi', 'rt'\n",
    "}\n",
    "stopwords = turkce_stopwords.union(ozel_stopwords)\n",
    "\n",
    "\n",
    "def temizle(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'[^\\w\\sçğıöşüÇĞİÖŞÜ]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def stopwords_temizle(text):\n",
    "    kelimeler = text.split()\n",
    "    filtreli = [k for k in kelimeler if k not in stopwords]\n",
    "    return \" \".join(filtreli)\n",
    "\n",
    "\n",
    "model_name = \"savasy/bert-base-turkish-sentiment-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "labels = ['Negatif', 'Pozitif']\n",
    "\n",
    "def analiz_et(text, threshold=0.65):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    confidence, predicted_class = torch.max(probs, dim=1)\n",
    "    if confidence.item() < threshold:\n",
    "        return \"Nötr\", confidence.item()\n",
    "    else:\n",
    "        return labels[predicted_class.item()], confidence.item()\n",
    "\n",
    "\n",
    "def yorumla(puan):\n",
    "    if puan < 1:\n",
    "        return \"Genel olarak olumsuz bir hava hakim.\"\n",
    "    elif puan < 1.5:\n",
    "        return \"Duygular nötr seviyede.\"\n",
    "    else:\n",
    "        return \"Pozitif bir hava gözlemleniyor.\"\n",
    "\n",
    "\n",
    "veriler = pd.read_csv(\"sozcu_news.csv\")\n",
    "ham_haberler = veriler['baslik'].dropna().tolist()\n",
    "\n",
    "\n",
    "temizlenmis_haberler = [stopwords_temizle(temizle(h)) for h in ham_haberler if len(h.strip()) > 2]\n",
    "\n",
    "\n",
    "sonuclar = []\n",
    "for haber in temizlenmis_haberler:\n",
    "    duygu, guven = analiz_et(haber)\n",
    "    sonuclar.append({'haber': haber, 'duygu': duygu, 'guven': guven})\n",
    "\n",
    "df_duygu = pd.DataFrame(sonuclar)\n",
    "\n",
    "\n",
    "duygu_puan_map = {'Negatif': 0, 'Nötr': 1, 'Pozitif': 2}\n",
    "df_duygu['duygu_puani'] = df_duygu['duygu'].map(duygu_puan_map)\n",
    "\n",
    "ortalama_puan = df_duygu['duygu_puani'].mean()\n",
    "\n",
    "\n",
    "yorum = yorumla(ortalama_puan)\n",
    "\n",
    "\n",
    "df_sonuc = pd.DataFrame({\n",
    "    'ortalama_duygu_puani': [ortalama_puan],\n",
    "    'yorum': [yorum]\n",
    "})\n",
    "\n",
    "\n",
    "os.makedirs(\"data/news\", exist_ok=True)\n",
    "df_sonuc.to_csv(\"haber_yorum.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Haberlerin ortalama duygu puanı ve yorumu kaydedildi: data/news/haber_yorum.csv\")\n",
    "print(df_sonuc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eed0fc-e1fb-4b34-8006-d013a8a2a512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
